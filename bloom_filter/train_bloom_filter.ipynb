{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from bloom_filter import BloomFilter\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the bloom filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the validation set and get all the predicted bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = pd.read_csv('../data/validation_set_transformed.csv', index_col='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../data/bot_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_preds = model.predict(validation_set.drop(columns=['bot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thera are 66 bots predicted\n",
      "['Kobott', 'WugBot', 'GoingBatty', 'Donner60', 'Formula Downforce', 'Bottlesofsmoke', 'Hotwiki', 'Soup detective', 'GreenC bot', 'RscprinterBot', 'BotHeroMaster', 'Waxworker', 'SimLibrarian', 'Minorax', 'Fadesga', 'Claireslobotomyemployee', 'Sanglahi86', 'Iveagh Gardens', 'DYKToolsBot', 'ProcBot', 'Bother659', 'GünniX', 'Filmssssssssssss', 'Edward-Woodrow', 'Vanderwaalforces', 'InceptionBot', 'Nubia86', 'DareshMohan', 'JCW-CleanerBot', 'Οἶδα', 'HeyElliott', 'TaxonBot', 'DYKUpdateBot', 'Mistico Dois', 'Drmies', 'Immanuelle', 'DarkAlphabot', 'Timtrent', 'Graham87', 'Billjones94', 'Wcquidditch', 'Chongkian', 'Plantdrew', 'Mathbot', 'SAMBOT2000xp', 'EarwigBot', 'HooptyBot', 'Eteethan', 'Frenchl', 'Pi bot', 'ShelfSkewed', 'Rodw', 'Solidest', 'GhostInTheMachine', 'IngenuityBot', 'IJVin', 'Ethobot', 'Jimmymci234', 'Sammi Brie', 'Botx123', 'Botushali', 'Citation bot', 'Marcocapelle', 'Bot2789', 'Spiderwinebottle', 'Hatchibombotar']\n"
     ]
    }
   ],
   "source": [
    "validation_set['bot_pred'] = bot_preds\n",
    "bots_list = validation_set[validation_set['bot_pred'] == True].index.tolist()\n",
    "print('Thera are', len(bots_list), 'bots predicted')\n",
    "print(bots_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write all the bots into the bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = BloomFilter(items_count=len(bots_list), fp_prob=0.1)\n",
    "for bot in bots_list:\n",
    "    bf.add(bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom implementation of the `BloomFilter` allows us to compute size of fitler and the number of hashes by given number of expected items to be written and expected FP probability.\n",
    "\n",
    "The size of bloom filter $m$ can be calculated as following by given expected number of elements $n$ and FP rate $p$:\n",
    "\n",
    "$$\n",
    "m = -\\frac{n \\ln p}{(\\ln 2) ^ 2}\n",
    "$$\n",
    "\n",
    "The number of hash functions $k$ can be computed the follwing way:\n",
    "$$\n",
    "k = \\frac{m}{n}\\ln 2\n",
    "$$\n",
    "\n",
    "Also, the FP probability can be computed the following way:\n",
    "$$\n",
    "\\hat{p} = \\left(1 - \\left[1 - \\frac{1}{m}\\right]^{kn}\\right)^{k}\n",
    "$$\n",
    "\n",
    "We noticed that the retrieved $m$ is pretty approximate to achieve expected FP rate $p$.\n",
    "\n",
    "To garantee that $\\hat{p} < p$ we decided to artificially increase the size of filter $m$ the following way:\n",
    "$$\n",
    "m = -\\frac{(n+1) \\ln p}{(\\ln 2) ^ 2}\n",
    "$$\n",
    "\n",
    "\n",
    "Also this BloomFilter can be userd with manually specified params of length of filter and number of hash functions the following way:\n",
    "```python\n",
    "BloomFilter(size=size, num_hashes=num_hashes)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bf.check(random.choice(bots_list))\n",
    "assert not bf.check('some_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BloomFilter({'size': 322, 'hash_count': 3, 'fp_prob': '0.09723', 'items_stored': 66})\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute theoretical value of FP probability based on current state of bloom filter, using already known formula, and considering that $n$ is the number of items already written to the filter\n",
    "$$\n",
    "\\hat{p} = \\left(1 - \\left[1 - \\frac{1}{m}\\right]^{kn}\\right)^{k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf.save('../data/bloom_filter.bf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set['bf_check'] = validation_set.index.map(lambda user: bf.check(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.91      0.95     15399\n",
      "        True       0.05      1.00      0.09        66\n",
      "\n",
      "    accuracy                           0.91     15465\n",
      "   macro avg       0.52      0.96      0.52     15465\n",
      "weighted avg       1.00      0.91      0.95     15465\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14041,  1358],\n",
       "       [    0,    66]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(validation_set['bot_pred'], validation_set['bf_check']))\n",
    "conf_matrix = confusion_matrix(validation_set['bot_pred'], validation_set['bf_check'])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP rate: 0.08781118655027481\n"
     ]
    }
   ],
   "source": [
    "total = conf_matrix.sum()\n",
    "fp = conf_matrix[0][1]\n",
    "print('FP rate:', fp / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
